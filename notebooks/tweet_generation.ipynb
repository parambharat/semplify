{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb7e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line to install dependencies\n",
    "# !pip install -qqq openai wandb transformers markdown beautifulsoup4 emoji PyGithub\n",
    "\n",
    "% load_ext dotenv\n",
    "% dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "## set your environment keys below to run inference\n",
    "\n",
    "# os.environ[\"GH_TOKEN\"]=\"your github personal access token\"\n",
    "# os.environ[\"OPENAI_API_KEY\"]=\"your openai api key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85b2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import GPT2TokenizerFast\n",
    "from github import Github\n",
    "import re\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji\n",
    "from packaging.version import Version\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c16e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mparambharat\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/mugan/data/wandb/projects/semplify/notebooks/wandb/run-20220929_232735-2z0tgpq9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/parambharat/semplify/runs/2z0tgpq9\" target=\"_blank\">spring-oath-83</a></strong> to <a href=\"https://wandb.ai/parambharat/semplify\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJECT_NAME = \"semplify\"\n",
    "\n",
    "# from sweep: fewshot_predictions-fine-sweep-29\n",
    "default_config = dict(\n",
    "    model_name=\"text-davinci-002\",\n",
    "    temperature=.34,\n",
    "    max_tokens=80,\n",
    "    top_p=0.42,\n",
    "    frequency_penalty=0.60,\n",
    "    presence_penalty=0.82,\n",
    "    stop_seq=\"###\",\n",
    "    num_generations=3,\n",
    "    prompt_length=3000,\n",
    "    shuffle_prompts=False)\n",
    "\n",
    "wandb.init(project=PROJECT_NAME, config=default_config)\n",
    "config = wandb.config\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1e4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the artifacts to create the prompt\n",
    "def load_prompt_data():\n",
    "    cleaned_artifacts = wandb.use_artifact(\n",
    "        \"parambharat/semplify/processed_dataset:v0\", type='dataset')\n",
    "\n",
    "    cleaned_artifacts = cleaned_artifacts.wait()\n",
    "\n",
    "    cleaned_table = cleaned_artifacts.get(\"cleaned_data\")\n",
    "    cleaned_df = pd.DataFrame(\n",
    "        cleaned_table.data,\n",
    "        columns=cleaned_table.columns)\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4c138d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_client = Github(os.environ['GH_TOKEN'])\n",
    "GH_USER = \"wandb\"\n",
    "GH_REPO = \"wandb\"\n",
    "\n",
    "\n",
    "def load_from_tag(tag):\n",
    "    try:\n",
    "        release_data = (github_client\n",
    "                        .get_user(GH_USER)\n",
    "                        .get_repo(GH_REPO)\n",
    "                        .get_release(f\"v{tag}\"))\n",
    "        if release_data.body.strip():\n",
    "            release_notes = release_data.body\n",
    "            return release_notes\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "USRBY_RE = r\"by \\@\\S+ in https\\S+$\"  # by <user> in <pr>\n",
    "URL_RE = r\"in https\\S+\"  # in <pr>\n",
    "CH_RE = \"^full changelog.*\"  # Full Changelog: ...\n",
    "DATE_RE = r\"\\(\\w+ \\d+, \\d+\\)\"  # (August 10, 2022)\n",
    "\n",
    "\n",
    "def cleanup_changelog(md_text):\n",
    "    html = markdown.markdown(md_text)\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    text = re.sub(USRBY_RE, \"\", soup.text, 0, re.MULTILINE)\n",
    "    text = re.sub(URL_RE, \"\", text, 0, re.MULTILINE)\n",
    "    text = re.sub(CH_RE, \"\", text, 0, re.MULTILINE | re.IGNORECASE)\n",
    "    text = re.sub(DATE_RE, \"\", text, 0, re.MULTILINE | re.IGNORECASE)\n",
    "    text = text.strip()\n",
    "    text = map(lambda x: x.strip(), text.splitlines())\n",
    "    text = \"\\n\".join(text)\n",
    "    text = emoji.demojize(emoji.emojize(text, language=\"alias\"))\n",
    "    text = text.replace('&amp;', '&')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e3d90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_history(df, prompt_length=2000, shuffled=False):\n",
    "    if shuffled:\n",
    "        df = df.sample(frac=1, replace=False)\n",
    "    total_length = 0\n",
    "    prompts = []\n",
    "    for idx, item in df.iloc[::-1].iterrows():\n",
    "        if item[\"prompt_length\"] + total_length < prompt_length:\n",
    "            total_length += item[\"prompt_length\"]\n",
    "            row_prompt = (\n",
    "                    \"[changelog]:\\n\\n\"\n",
    "                    + item[\"cleaned_logs\"].strip()\n",
    "                    + \"\\n\\n[tweet]:\\n\\n\"\n",
    "                    + item[\"cleaned_tweet\"].strip()\n",
    "                    + \"\\n\\n###\\n\\n\"\n",
    "            )\n",
    "            prompts.append(row_prompt)\n",
    "\n",
    "    return \"\\n\".join(prompts[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b6a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_len(texts):\n",
    "    return list(map(len, tokenizer(texts).input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "179ddaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(new_log, df, config):\n",
    "    new_log_length = get_tokenized_len([new_log])[0]\n",
    "    history_length = config.prompt_length - new_log_length - 10\n",
    "\n",
    "    df[\"tweet_length\"] = get_tokenized_len(df[\"cleaned_tweet\"].tolist())\n",
    "    df[\"log_length\"] = get_tokenized_len(df[\"cleaned_logs\"].tolist())\n",
    "    df.loc[:, \"prompt_length\"] = df[\"tweet_length\"] + df[\"log_length\"] + 10\n",
    "\n",
    "    history_prompt = make_history(df, history_length, shuffled=config.shuffle_prompts)\n",
    "    prompt = (\n",
    "            history_prompt\n",
    "            + \"[changelog]:\\n\\n\"\n",
    "            + new_log.strip()\n",
    "            + \"\\n\\n[tweet]:\\n\\n\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc757e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(prompt, config):\n",
    "    response = openai.Completion.create(\n",
    "        model=config.model_name,\n",
    "        prompt=prompt,\n",
    "        temperature=config.temperature,\n",
    "        max_tokens=config.max_tokens,\n",
    "        top_p=config.top_p,\n",
    "        frequency_penalty=config.frequency_penalty,\n",
    "        presence_penalty=config.presence_penalty,\n",
    "        stop=config.stop_seq,\n",
    "        n=config.num_generations,\n",
    "    )\n",
    "\n",
    "    generated_tweets = [\n",
    "        choice.to_dict()[\"text\"].strip() for choice in response.to_dict()[\"choices\"]\n",
    "    ]\n",
    "    return generated_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de7f0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tweet(tweet, semver):\n",
    "    formatted_tweet = (f\"⭐️wandb v{semver} released⭐️\\n\\n\" +\n",
    "                       emoji.emojize(tweet, language=\"alias\") +\n",
    "                       \"\\n\\n`pip install wandb --upgrade`\")\n",
    "    return formatted_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c7eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweets_from_tag(git_tag, config):\n",
    "    df = load_prompt_data()\n",
    "\n",
    "    if Version(df[\"semver\"].iloc[-1]) < Version(git_tag):\n",
    "        new_log = cleanup_changelog(load_from_tag(git_tag))\n",
    "    else:\n",
    "        print(\"Tweet already exists for version in the dataset\")\n",
    "\n",
    "    prompt = make_prompt(new_log, df, config)\n",
    "    generated_tweets = run_inference(prompt, config)\n",
    "\n",
    "    tweet_formatter = partial(format_tweet, semver=git_tag)\n",
    "    formatted_tweets = list(map(tweet_formatter, generated_tweets))\n",
    "    return formatted_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e13050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the version of git tag you wish to tweet about: 0.13.3\n"
     ]
    }
   ],
   "source": [
    "# Enter the Git tag you want to generate a tweet for \n",
    "GIT_TAG = input(\"Enter the version of git tag you wish to tweet about: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471e6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\tgenerated tweet: 1\t########################################\n",
      "⭐️wandb v0.13.3 released⭐️\n",
      "\n",
      "7️⃣ new contributors!\n",
      "\n",
      "💫 Adds raytune examples / tests\n",
      "💫 Adds Sweeps on Launch Jobs for Kubernetes\n",
      "💫 Adds parallelism to functional testing\n",
      "🐞 Fixes broken Launch apikey error message\n",
      "\n",
      "`pip install wandb --upgrade`\n",
      "\n",
      "########################################\tgenerated tweet: 2\t########################################\n",
      "⭐️wandb v0.13.3 released⭐️\n",
      "\n",
      "7️⃣ new contributors!\n",
      "\n",
      "💫 Adds support for arguments in Launch Jobs\n",
      "💫 Adds Sweeps on Launch on Kubernetes\n",
      "💫 Adds parallelism to functional testing\n",
      "🐞 Fixes broken artifact test for regression\n",
      "\n",
      "`pip install wandb --upgrade`\n",
      "\n",
      "########################################\tgenerated tweet: 3\t########################################\n",
      "⭐️wandb v0.13.3 released⭐️\n",
      "\n",
      "7️⃣ new contributors!\n",
      "\n",
      "💫 Adds support for arguments in Launch Jobs\n",
      "💫 Adds Sweeps on Launch on Kubernetes\n",
      "💫 Adds parallelism to functional testing\n",
      "🐞 Fixes broken artifact test for regression\n",
      "\n",
      "`pip install wandb --upgrade`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = generate_tweets_from_tag(git_tag=GIT_TAG, config=config)\n",
    "for i, tweet in enumerate(tweets):\n",
    "    print(\"#\" * 40 + f\"\\tgenerated tweet: {i + 1}\\t\" + \"#\" * 40)\n",
    "    print(tweet)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e19a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
